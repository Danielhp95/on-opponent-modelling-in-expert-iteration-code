experiment:
  algorithms:
    - expert_iteration_vanilla_500_GamesPerGeneration_20_MCTSBudget_NoRollout_3_epochs_128_BatchSize
    #
    - expert_iteration_neural_net_opponent_modelling_500_GamesPerGeneration_20_MCTSBudget_NoRollout_3_epochs_128_BatchSize
    #
    - expert_iteration_brexit_true_models_500_GamesPerGeneration_20_MCTSBudget_NoRollout_3_epochs_128_BatchSize
    #
    - expert_iteration_brexit_learnt_models_500_GamesPerGeneration_20_MCTSBudget_NoRollout_3_epochs_128_BatchSize
  num_envs: -1
  environment:
    name: 'Connect4-v0' 
    env_type: 'multiagent-sequential'
    frame_stack: 4
  experiment_id: 'vs_strong_agent'
  desired_winrate: 0.70
  # ideally, a multiple of policy updates. Param :games_per iteration:
  training_episodes: 500
  benchmarking_episodes: 100


# --------- Agent hyperparameters ------
cnn_arch: &cnn_architecture
    phi_arch: 'CNN'
    use_batch_normalization: True
    preprocessed_input_dimensions: [7, 6]
    # Channels are: 3 (empty, p1 pieces, p2 pieces) * 4 stacked frames
    channels: [12, 15, 20, 20, 20, 1]
    kernel_sizes: [3, 3, 3, 3, 3]
    paddings: [1, 1, 1, 1, 1]
    strides: [1, 1, 1, 1, 1]
    residual_connections: [[0,1], [1,2], [2,3], [3,4]]

agents:
######## Vanilla ExIt ################
  expert_iteration: &vanilla_expert_iteration
    <<: *cnn_architecture
    use_agent_modelling: False
    use_true_agent_models_in_mcts: False
    use_apprentice_in_expert: True
    use_learnt_opponent_models_in_mcts: False
    use_cuda: False
    games_per_iteration: 500
    # Dataset params
    initial_memory_size: 30000
    end_memory_size: 150000
    increase_memory_every_n_generations: 2
    increase_memory_size_by: 10000
    # MCTS config
    mcts_budget: 20
    mcts_rollout_budget: 0
    mcts_exploration_factor: 4.
    mcts_use_dirichlet: False
    mcts_dirichlet_alpha: 1.
    # Neural net config
    batch_size: 64
    num_epochs_per_iteration: 3
    learning_rate: 1.0e-3
    # NN: Feature extractor
    feature_extractor_arch: 'CNN'
    post_feature_extractor_arch: 'MLP'
    post_feature_extractor_policy_inference_hidden_units: [64, 64, 64, 64]
    post_feature_extractor_policy_inference_hidden_units: [64, 64, 64]
    post_feature_extractor_actor_critic_hidden_units: [64, 64, 64]
    # We want to batch the stacked observations into different channels
    state_preprocessing_fn: 'turn_into_single_element_batch_and_flatten_last_dim'
    server_state_preprocessing_fn: 'flatten_last_dim_and_batch_vector_observation'

  expert_iteration_debug:
    <<: *vanilla_expert_iteration
    mcts_budget: 1
    mcts_rollout_budget: 100
    use_apprentice_in_expert: True
    use_agent_modelling: True
    use_true_agent_models_in_mcts: True
    use_learnt_opponent_models_in_mcts: True
    use_dirichlet: False
    games_per_iteration: 1
    batch_size: 8

  expert_iteration_vanilla_500_GamesPerGeneration_20_MCTSBudget_NoRollout_3_epochs_128_BatchSize:
    <<: *vanilla_expert_iteration
    mcts_budget: 20
    games_per_iteration: 500
    num_epochs_per_iteration: 3
    batch_size: 128
#
######## ExIt with opponent modelling on neural net (ala DPIQN) ################
  expert_iteration_neural_net_opponent_modelling_500_GamesPerGeneration_20_MCTSBudget_NoRollout_3_epochs_128_BatchSize:
    <<: *vanilla_expert_iteration
    use_agent_modelling: True
    use_true_agent_models_in_mcts: False
    use_apprentice_in_expert: True
    mcts_budget: 20
    games_per_iteration: 500
    num_epochs_per_iteration: 3
    batch_size: 128

######## ExIt with opponent modelling on neural net AND using true opponent models during search ################
  expert_iteration_brexit_true_models_500_GamesPerGeneration_20_MCTSBudget_NoRollout_3_epochs_128_BatchSize:
    <<: *vanilla_expert_iteration
    use_agent_modelling: True
    use_true_agent_models_in_mcts: True
    use_apprentice_in_expert: True
    mcts_budget: 20
    games_per_iteration: 500
    num_epochs_per_iteration: 3
    batch_size: 128

######## ExIt with opponent modelling on neural net AND using true opponent models during search ################
  expert_iteration_brexit_learnt_models_500_GamesPerGeneration_20_MCTSBudget_NoRollout_3_epochs_128_BatchSize:
    <<: *vanilla_expert_iteration
    use_agent_modelling: True
    use_true_agent_models_in_mcts: False
    use_learnt_opponent_models_in_mcts: True
    use_apprentice_in_expert: True
    mcts_budget: 20
    games_per_iteration: 500
    num_epochs_per_iteration: 3
    batch_size: 128
