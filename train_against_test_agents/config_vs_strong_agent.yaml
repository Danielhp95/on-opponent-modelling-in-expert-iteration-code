experiment:
  algorithms:
    #- expert_iteration_debug
    #
    - expert_iteration_vanilla_800_GamesPerGeneration_50_MCTSBudget_NoRollout_3_epochs_128_BatchSize
    #
    - expert_iteration_neural_net_opponent_modelling_800_GamesPerGeneration_50_MCTSBudget_NoRollout_3_epochs_128_BatchSize
    #
    - expert_iteration_brexit_learnt_models_800_GamesPerGeneration_50_MCTSBudget_NoRollout_3_epochs_128_BatchSize
    #
    - expert_iteration_brexit_true_models_800_GamesPerGeneration_50_MCTSBudget_NoRollout_3_epochs_128_BatchSize
  num_envs: -1
  environment:
    name: 'Connect4-v0' 
    env_type: 'multiagent-sequential'
  experiment_id: '1st_december'
  desired_winrate: 0.50
  # ideally, a multiple of policy updates. Param :games_per iteration:
  training_episodes: 3
  benchmarking_episodes: 100


# --------- Agent hyperparameters ------
cnn_arch: &cnn_architecture
    phi_arch: 'CNN'
    use_batch_normalization: True
    preprocessed_input_dimensions: [7, 6]
    # Channels are: 3 (empty, p1 pieces, p2 pieces) * 4 stacked frames
    channels: [3, 15, 20, 64, 64]
    kernel_sizes: [3, 3, 3, 3]
    paddings: [1, 1, 1, 1]
    strides: [1, 1, 1, 1]
    residual_connections: [[0,1], [1,2], [2,3], [3,4]]
    final_feature_dim: 256

agents:
######## Vanilla ExIt ################
  expert_iteration: &vanilla_expert_iteration
    <<: *cnn_architecture
    use_agent_modelling: False
    use_true_agent_models_in_mcts: False
    use_apprentice_in_expert: True
    use_learnt_opponent_models_in_mcts: False
    average_episode_returns_with_mcts_values: True
    use_cuda: False
    games_per_iteration: 800
    # Dataset params
    initial_max_generations_in_memory: 5
    memory_increase_step: 5
    increase_memory_every_n_generations: 5
    final_max_generations_in_memory: 200  # We won't achieve values this high
    # MCTS config
    mcts_budget: 1
    mcts_rollout_budget: 0
    mcts_exploration_factor: 2
    mcts_use_dirichlet: False
    mcts_dirichlet_alpha: 1.
    mcts_dirichlet_strength: 0.5
    temperature: 1.
    drop_temperature_after_n_moves: 10
    # Neural net config
    batch_size: 512
    num_epochs_per_iteration: 5
    learning_rate: 1.5e-3
    # NN: Feature extractor
    feature_extractor_arch: 'CNN'
    post_feature_extractor_arch: 'MLP'
    # If opponent modelling is NOT used
    post_feature_extractor_hidden_units: [128, 128, 128]
    # If opponent mdoelling is used
    post_feature_extractor_policy_inference_hidden_units: [128, 64]
    post_feature_extractor_actor_critic_hidden_units: [128, 64]
    critic_gate_fn: 'tanh'
    ##
    # We want to batch the stacked observations into different channels
    state_preprocessing_fn: 'turn_into_single_element_batch'
    server_state_preprocessing_fn: 'batch_vector_observation'
    data_augmentation_fn:
       name: 'generate_horizontal_symmetry'
       flip_on_obs_dim: 1
    
  expert_iteration_debug:
    <<: *vanilla_expert_iteration
    mcts_budget: 1
    mcts_rollout_budget: 100
    use_apprentice_in_expert: True
    use_agent_modelling: True
    use_true_agent_models_in_mcts: True
    use_learnt_opponent_models_in_mcts: False
    use_dirichlet: False
    games_per_iteration: 1
    batch_size: 8

  expert_iteration_vanilla_800_GamesPerGeneration_50_MCTSBudget_NoRollout_3_epochs_128_BatchSize:
    <<: *vanilla_expert_iteration
#
######## ExIt with opponent modelling on neural net (ala DPIQN) ################
  expert_iteration_neural_net_opponent_modelling_800_GamesPerGeneration_50_MCTSBudget_NoRollout_3_epochs_128_BatchSize:
    <<: *vanilla_expert_iteration
    use_agent_modelling: True

######## ExIt with opponent modelling on neural net AND using true opponent models during search ################
  expert_iteration_brexit_true_models_800_GamesPerGeneration_50_MCTSBudget_NoRollout_3_epochs_128_BatchSize:
    <<: *vanilla_expert_iteration
    use_agent_modelling: True
    use_true_agent_models_in_mcts: True

######## ExIt with opponent modelling on neural net AND using true opponent models during search ################
  expert_iteration_brexit_learnt_models_800_GamesPerGeneration_50_MCTSBudget_NoRollout_3_epochs_128_BatchSize:
    <<: *vanilla_expert_iteration
    use_agent_modelling: True
    use_learnt_opponent_models_in_mcts: True
